# -*- coding: utf-8 -*-
"""Sachin Sir Localization.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I32sI3JTuIBNGcnvHCL-C4BF1ncu3yoW
"""

import tensorflow as tf
from tensorflow.keras import layers, Model
from tensorflow.keras.layers import Conv2D, UpSampling2D, Concatenate, ReLU, LayerNormalization

# Define a convolution block
def conv_block(inputs, filters, kernel_size=3, strides=1, activation=True):
    x = Conv2D(filters, kernel_size=kernel_size, strides=strides, padding="same")(inputs)
    if activation:
        x = ReLU()(x)
    return x

# Define the encoder block
def encoder_block(inputs):
    conv1 = conv_block(inputs, filters=64, kernel_size=3)
    conv2 = conv_block(conv1, filters=128, kernel_size=3, strides=2)  # Downsample by 1/2
    conv3 = conv_block(conv2, filters=256, kernel_size=3, strides=2)  # Downsample by 1/4
    return conv1, conv2, conv3

# Define a decoder block with resizing
def decoder_block(inputs, skip_connection, filters):
    up = UpSampling2D(size=(2, 2))(inputs)  # Upsample by 2
    # Resize upsampled feature map to match skip connection using a Lambda layer
    up = layers.Lambda(lambda x: tf.image.resize(x[0], size=tf.shape(x[1])[1:3]))([up, skip_connection])
    merge = Concatenate()([up, skip_connection])  # Skip connection
    x = conv_block(merge, filters, kernel_size=3)
    return x

# Swin Transformer Block
class SwinTransformerBlock(layers.Layer):
    def __init__(self, embed_dim, num_heads, window_size=4, mlp_ratio=4.0):
        super(SwinTransformerBlock, self).__init__()
        self.embed_dim = embed_dim
        self.num_heads = num_heads
        self.window_size = window_size
        self.mlp_ratio = mlp_ratio

        # Layers
        self.attention = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.mlp = tf.keras.Sequential([
            layers.Dense(int(embed_dim * mlp_ratio), activation="relu"),
            layers.Dense(embed_dim),
        ])
        self.norm1 = LayerNormalization(epsilon=1e-6)
        self.norm2 = LayerNormalization(epsilon=1e-6)

    def build(self, input_shape):
        # Validate the input dimensions
        if len(input_shape) != 3:
            raise ValueError(f"Expected input shape [batch_size, num_patches, embed_dim], but got {input_shape}")
        if input_shape[-1] != self.embed_dim:
            raise ValueError(f"Input embed_dim ({input_shape[-1]}) must match layer embed_dim ({self.embed_dim})")

    def call(self, inputs):
        # Self-attention
        attn_output = self.attention(inputs, inputs)
        attn_output = self.norm1(inputs + attn_output)

        # MLP
        mlp_output = self.mlp(attn_output)
        output = self.norm2(attn_output + mlp_output)

        return output

# Build the complete model
def FLTNet(input_shape=(256, 256, 3)):
    inputs = layers.Input(shape=input_shape)

    # Encoder
    conv1, conv2, conv3 = encoder_block(inputs)

    # Swin Transformer bottleneck
    H, W, C = conv3.shape[1:]  # Extract spatial and channel dimensions
    reshaped = layers.Reshape((H * W, C))(conv3)  # Flatten spatial dimensions
    swin_block = SwinTransformerBlock(embed_dim=C, num_heads=8, window_size=4)
    swin_output = swin_block(reshaped)
    swin_output = layers.Reshape((H, W, C))(swin_output)  # Restore spatial dimensions

    # Decoder
    dconv1 = decoder_block(swin_output, conv3, filters=256)
    dconv2 = decoder_block(dconv1, conv2, filters=128)
    dconv3 = decoder_block(dconv2, conv1, filters=64)

    # Output segmentation head
    outputs = Conv2D(1, kernel_size=(1, 1), activation="sigmoid", padding="same")(dconv3)

    return Model(inputs, outputs)

# Instantiate and compile the model
model = FLTNet(input_shape=(256, 256, 3))
model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

# Print the model summary
model.summary()

import tensorflow as tf
from tensorflow.keras import backend as K

def dice_loss(y_true, y_pred):
    """
    Dice Loss: Measures similarity between ground truth and prediction.
    Formula: 1 - (2 * intersection + smooth) / (union + smooth)
    """
    smooth = 1e-6
    y_true_f = K.flatten(y_true)
    y_pred_f = K.flatten(y_pred)
    intersection = K.sum(y_true_f * y_pred_f)
    union = K.sum(y_true_f) + K.sum(y_pred_f)
    dice = (2. * intersection + smooth) / (union + smooth)
    return 1 - dice

def binary_focal_loss(y_true, y_pred, gamma=2.0, alpha=0.25):
    """
    Binary Focal Loss: Focuses on hard-to-classify regions by penalizing misclassifications.
    Formula: -alpha * (1 - p_t)^gamma * log(p_t)
    """
    epsilon = K.epsilon()  # Small constant to avoid log(0)
    y_true = tf.cast(y_true, tf.float32)  # Ensure type consistency
    y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)  # Clip predictions

    # Compute the focal loss components
    p_t = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)
    loss = -alpha * tf.pow(1 - p_t, gamma) * tf.math.log(p_t)
    return K.mean(loss)

def composite_loss(y_true, y_pred, gamma=2.0, alpha=0.73, bfl_weight=1.0):
    """
    Composite Loss: Combines Dice Loss and Binary Focal Loss.
    Formula: Loss = Dice_Loss + (BFL_weight * Binary_Focal_Loss)
    """
    dsc = dice_loss(y_true, y_pred)
    bfl = binary_focal_loss(y_true, y_pred, gamma=gamma, alpha=alpha)
    loss = dsc + bfl_weight * bfl
    return loss

# Instantiate and compile the model with the composite loss
model.compile(optimizer="adam", loss=lambda y_true, y_pred: composite_loss(y_true, y_pred, gamma=2.0, alpha=0.73), metrics=["accuracy"])

model.fit(X_train, y_train, batch_size=64, epochs=200)

